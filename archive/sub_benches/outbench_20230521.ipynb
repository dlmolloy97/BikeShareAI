{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two classes:\n",
    "# The first one should include the following methods:\n",
    "# __init__: Takes a URL of a zip file as argument, and unzips the file into a CSV in the data folder\n",
    "# connect_to_db: Creates and returns a connection to the local PostgreSQL database using the sqlalchemy package.\n",
    "# df_to_db: Takes the arguments table_name and dataframe. If no table with the name table_name exists in the local PostgreSQL, then insert the csv located at csv_path as a table with the name table_name\n",
    "# main_join: Takes the arguments geojson_path, station_path, and journeys_path. Loads the csv at station_path as a dataframe called stations, and the csv at journeys_path as journeys. Loads the data from geojson path as polydf, loads the table stations as a Geopandas GeoDataFrame with epsg='4326', and then performs a spatial join between polydf and the stations GeoDataFrame. \n",
    "# The resulting Dataframe should be joined to the journey dataframe using journeys.start_station_name = neighbourhood_stations.station twice, producing a table with all of the columns from journeys, plus the start and end neighbourhoods and stations for each journey. Finally, the resulting DataFrame should be written to the PostgreSQL database as a table called journeys_enriched\n",
    "# The second one should include the following methods:\n",
    "# - create_dash_application: create a Dash application. In this application, \n",
    "#it should be possible to select the number of journeys or the average duration as response_variable, and then summarise response_variable by any of the following variables:\n",
    "# start_neighbourhood\n",
    "# end_neighbourhood\n",
    "# day_of_week\n",
    "# hour_of_day\n",
    "# month_of_year\n",
    "# - run: call the create_dash_application method and run the app\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "from urllib import request\n",
    "from zipfile import ZipFile\n",
    "from geopandas import GeoDataFrame, read_file, points_from_xy\n",
    "import dash\n",
    "#import dash_core_components as dcc\n",
    "from dash import dcc\n",
    "#import dash_html_components as html\n",
    "from dash import html\n",
    "import plotly.express as px\n",
    "\n",
    "class BlueBikesDataPipeline:\n",
    "\n",
    "    def __init__(self, url):\n",
    "        self.url = url\n",
    "        self.engine = create_engine('postgresql://postgres:postgres@localhost:5432/desmondmolloy')\n",
    "        # Create a connection to the engine called `conn`\n",
    "        self.conn = self.engine.connect()\n",
    "    \n",
    "    def unzip_file_to_local_csv(self):\n",
    "        # Download the zip file from the URL\n",
    "        request.urlretrieve(self.url, 'data.zip')\n",
    "        # Unzip the file\n",
    "        ZipFile('data.zip').extractall('data')\n",
    "        # Return the unzipped file\n",
    "        # return 'data/tripdata.csv'\n",
    "    \n",
    "    def df_to_db(self, table_name, dataframe):\n",
    "        # Append the data to the `trips` table\n",
    "        dataframe.to_sql(table_name, self.conn, index=False, if_exists='append')\n",
    "    \n",
    "    def main_join(self, geojson_path, station_path, journeys_path):\n",
    "        poly_df = read_file(geojson_path)\n",
    "#        poly_df = poly_df[poly_df['District'] == 'Boston']\n",
    "        poly_df = poly_df[['Name', 'geometry']]\n",
    "        poly_df.columns = ['neighbourhood', 'geometry']\n",
    "        poly_df['neighbourhood'] = poly_df['neighbourhood'].str.lower()\n",
    "        poly_df['neighbourhood'] = poly_df['neighbourhood'].str.replace(' ', '_')\n",
    "        poly_df['neighbourhood'] = poly_df['neighbourhood'].str.replace('-', '_')\n",
    "        poly_df['neighbourhood'] = poly_df['neighbourhood'].str.replace('\\'', '')\n",
    "        poly_df['neighbourhood'] = poly_df['neighbourhood'].str.replace('(', '')\n",
    "        poly_df['neighbourhood'] = poly_df['neighbourhood'].str.replace(')', '')\n",
    "        poly_df['neighbourhood'] = poly_df['neighbourhood'].str.replace('.', '')\n",
    "        poly_df['neighbourhood'] = poly_df['neighbourhood'].str.replace('&', 'and')\n",
    "        # Here is where manual was added\n",
    "        stations = pd.read_csv(station_path)\n",
    "        #stations = stations[['Station ID', 'Station Name', 'Latitude', 'Longitude']]\n",
    "        stations = stations[['Number', 'Name', 'Latitude', 'Longitude']]\n",
    "        stations.columns = ['station_id', 'station_name', 'latitude', 'longitude']\n",
    "        stations['station_name'] = stations['station_name'].str.lower()\n",
    "        stations['station_name'] = stations['station_name'].str.replace(' ', '_')\n",
    "        stations['station_name'] = stations['station_name'].str.replace('-', '_')\n",
    "        stations['station_name'] = stations['station_name'].str.replace('\\'', '')\n",
    "        stations['station_name'] = stations['station_name'].str.replace('(', '')\n",
    "        stations['station_name'] = stations['station_name'].str.replace(')', '')\n",
    "        stations['station_name'] = stations['station_name'].str.replace('.', '')\n",
    "        stations['station_name'] = stations['station_name'].str.replace('&', 'and')\n",
    "        # Here, the loop began again, forcing manual changes\n",
    "        stations_geo = GeoDataFrame(stations, geometry=points_from_xy(stations.longitude, stations.latitude))\n",
    "        stations_geo.set_crs(epsg='4326', inplace=True)\n",
    "        joined_df = stations_geo.sjoin(poly_df, how=\"left\")\n",
    "        #grab_df = joined_df[['Name_left', 'Name_right', 'District']]\n",
    "        #matched_pairs_with_pandas = grab_df[grab_df['District'] == 'Boston']\n",
    "        #matched_pairs_with_pandas.columns = ['station', 'neighbourhood', 'District']\n",
    "        # Create a SparkSession\n",
    "        #spark = SparkSession.builder.appName(\"BlueBikes\").getOrCreate()\n",
    "        # Create a schema for the dataframe\n",
    "        #schema = StructType([])\n",
    "        # Load the CSV file into a dataframe\n",
    "        #journeys = spark.read.csv(journeys_path, header=True, schema=schema)\n",
    "        journeys_pandas_df = pd.read_csv(journeys_path)\n",
    "        #started_at was actual name\n",
    "        journeys_pandas_df = journeys_pandas_df[['started_at', 'ended_at', 'start_station_name', 'end_station_name']]\n",
    "        journeys_pandas_df.columns = ['started_at', 'ended_at', 'start_station_name', 'end_station_name']\n",
    "        journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.lower()\n",
    "        journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace(' ', '_')\n",
    "        journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('-', '_')\n",
    "        journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('\\'', '')\n",
    "        journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('(', '')\n",
    "        journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace(')', '')\n",
    "        journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('.', '')\n",
    "        journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('&', 'and')\n",
    "        journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.lower()\n",
    "        journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace(' ', '_')\n",
    "        journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('-', '_')\n",
    "        journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('\\'', '')\n",
    "        journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('(', '')\n",
    "        journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace(')', '')\n",
    "        journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('.', '')\n",
    "        journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('&', 'and')\n",
    "        #journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace(' ', '_')\n",
    "        #journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace(' ', '_')\n",
    "        #journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('-', '_')\n",
    "        #journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('-', '_')\n",
    "        #journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('\\'', '')\n",
    "        #journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('\\'', '')\n",
    "        #journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('(', '')\n",
    "        #journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('(', '')\n",
    "        #journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace(')', '')\n",
    "        #journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace(')', '')\n",
    "        #journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('.', '')\n",
    "        #journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('.', '')\n",
    "        #journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('&', 'and')\n",
    "        #journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('&', 'and')\n",
    "        #journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace(' ', '_')\n",
    "        #journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace(' ', '_')\n",
    "        #journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('-', '_')\n",
    "        #journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('-', '_')\n",
    "        #journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('\\'', '')\n",
    "        #Broke loop here with journeys_enriched call\n",
    "        journeys_enriched = pd.merge(journeys_pandas_df, joined_df, how='left', left_on='start_station_name', right_on='station_name')\n",
    "        journeys_enriched = pd.merge(journeys_enriched, joined_df, how='left', left_on='end_station_name', right_on='station_name')\n",
    "        journeys_enriched = journeys_enriched[['started_at', 'ended_at', 'start_station_name', 'end_station_name', 'neighbourhood_x', 'neighbourhood_y']]\n",
    "        journeys_enriched.columns = ['started_at', 'ended_at', 'start_station_name', 'end_station_name', 'start_neighbourhood', 'end_neighbourhood']\n",
    "        #journeys_enriched = journeys_enriched[['started_at', 'ended_at', 'start_station_name', 'end_station_name', 'duration', 'Name_left', 'Name_right']]\n",
    "        #journeys_enriched.columns = ['started_at', 'ended_at', 'start_station_name', 'end_station_name', 'duration', 'start_neighbourhood', 'end_neighbourhood']\n",
    "        journeys_enriched['started_at'] = pd.to_datetime(journeys_enriched['started_at'])\n",
    "        journeys_enriched['ended_at'] = pd.to_datetime(journeys_enriched['ended_at'])\n",
    "        journeys_enriched['day_of_week'] = journeys_enriched['started_at'].dt.day_name()\n",
    "        journeys_enriched['hour_of_day'] = journeys_enriched['started_at'].dt.hour\n",
    "        journeys_enriched['month_of_year'] = journeys_enriched['started_at'].dt.month_name()\n",
    "        #Beneath was added manually, but completed by Copilot\n",
    "        journeys_enriched[\"duration\"] = journeys_enriched[\"ended_at\"] - journeys_enriched[\"started_at\"]\n",
    "        journeys_enriched['duration'] = journeys_enriched['duration'] / 60\n",
    "        # Write the dataframe to the `trips` table\n",
    "        journeys_enriched.to_sql('journeys_enriched', self.conn, index=False, if_exists='replace')\n",
    "        # Close the connection\n",
    "        self.conn.close()\n",
    "        # Stop the SparkSession\n",
    "        #spark.stop()\n",
    "\n",
    "class BlueBikesDashboardLocal:\n",
    "    def __init__(self):\n",
    "        self.engine = create_engine('postgresql://postgres:postgres@localhost:5432/desmondmolloy')\n",
    "        # Create a connection to the engine called `conn`\n",
    "        self.conn = self.engine.connect()\n",
    "    \n",
    "    def create_dash_application(self, response_variable='journeys_count', group_by='start_neighbourhood'):\n",
    "        # Create the Dash app\n",
    "        app = dash.Dash(__name__)\n",
    "        # Create a DataFrame from the Postgres table\n",
    "        assert response_variable in ['journeys_count', 'journey_duration']\n",
    "        if response_variable == 'journeys_count':\n",
    "            df = pd.read_sql('SELECT {}, COUNT(*) as journeys_count FROM journeys_enriched group by 1'.format(group_by), self.conn)\n",
    "        else:\n",
    "            df = pd.read_sql('SELECT {}, AVG(journey_duration) as journey_duration FROM journeys_enriched group by 1'.format(group_by), self.conn)\n",
    "        df = pd.read_sql('SELECT {}, COUNT(*) as journeys_count FROM journeys_enriched group by 1'.format(group_by), self.conn)\n",
    "        # Create a bar chart of the number of trips by neighbourhood\n",
    "        fig = px.bar(df, x=group_by, y=response_variable)\n",
    "        # Create the Dash app layout\n",
    "        app.layout = html.Div(children=[\n",
    "            html.H1(children='Hello Dash'),\n",
    "            dcc.Graph(\n",
    "                id='example-graph',\n",
    "                figure=fig\n",
    "            )\n",
    "        ])\n",
    "        return app\n",
    "    \n",
    "    def run(self):\n",
    "    # Create the Dash app\n",
    "        app = self.create_dash_application()\n",
    "    # Run the app\n",
    "        app.run_server(debug=True, use_reloader=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[33m * Tip: There are .env or .flaskenv files present. Do \"pip install python-dotenv\" to use them.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "#from bikeshareai.bluebikes import BlueBikesDataPipeline, BlueBikesDashboard\n",
    "# Create an instance of BlueBikesDataPipeline and run the methods\n",
    "#pipeline = BlueBikesDataPipeline('https://s3.amazonaws.com/hubway-data/202304-bluebikes-tripdata.zip')\n",
    "#pipeline.unzip_file_to_local_csv()\n",
    "#Arguments were automatically suggested\n",
    "#pipeline.main_join('data/Boston_Neighborhoods.geojson', 'data/current_bluebikes_stations.csv', 'data/202304-bluebikes-tripdata.csv')\n",
    "#pipeline.df_to_db('journeys_enriched', 'data/202304-bluebikes-tripdata.csv')\n",
    "# Create an instance of BlueBikesDashboard and run the methods\n",
    "dashboard = BlueBikesDashboardLocal()\n",
    "dashboard.run()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/63/7wfwn_sn3cv5zpj5dk7k9r3r0000gn/T/ipykernel_2530/352477324.py:9: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  poly_df['neighbourhood'] = poly_df['neighbourhood'].str.replace('(', '')\n",
      "/var/folders/63/7wfwn_sn3cv5zpj5dk7k9r3r0000gn/T/ipykernel_2530/352477324.py:10: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  poly_df['neighbourhood'] = poly_df['neighbourhood'].str.replace(')', '')\n",
      "/var/folders/63/7wfwn_sn3cv5zpj5dk7k9r3r0000gn/T/ipykernel_2530/352477324.py:11: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  poly_df['neighbourhood'] = poly_df['neighbourhood'].str.replace('.', '')\n",
      "/var/folders/63/7wfwn_sn3cv5zpj5dk7k9r3r0000gn/T/ipykernel_2530/352477324.py:22: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  stations['station_name'] = stations['station_name'].str.replace('(', '')\n",
      "/var/folders/63/7wfwn_sn3cv5zpj5dk7k9r3r0000gn/T/ipykernel_2530/352477324.py:23: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  stations['station_name'] = stations['station_name'].str.replace(')', '')\n",
      "/var/folders/63/7wfwn_sn3cv5zpj5dk7k9r3r0000gn/T/ipykernel_2530/352477324.py:24: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  stations['station_name'] = stations['station_name'].str.replace('.', '')\n",
      "/var/folders/63/7wfwn_sn3cv5zpj5dk7k9r3r0000gn/T/ipykernel_2530/352477324.py:47: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('(', '')\n",
      "/var/folders/63/7wfwn_sn3cv5zpj5dk7k9r3r0000gn/T/ipykernel_2530/352477324.py:48: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace(')', '')\n",
      "/var/folders/63/7wfwn_sn3cv5zpj5dk7k9r3r0000gn/T/ipykernel_2530/352477324.py:49: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('.', '')\n",
      "/var/folders/63/7wfwn_sn3cv5zpj5dk7k9r3r0000gn/T/ipykernel_2530/352477324.py:55: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('(', '')\n",
      "/var/folders/63/7wfwn_sn3cv5zpj5dk7k9r3r0000gn/T/ipykernel_2530/352477324.py:56: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace(')', '')\n",
      "/var/folders/63/7wfwn_sn3cv5zpj5dk7k9r3r0000gn/T/ipykernel_2530/352477324.py:57: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('.', '')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>started_at</th>\n",
       "      <th>ended_at</th>\n",
       "      <th>start_station_name</th>\n",
       "      <th>end_station_name</th>\n",
       "      <th>station_id_x</th>\n",
       "      <th>station_name_x</th>\n",
       "      <th>latitude_x</th>\n",
       "      <th>longitude_x</th>\n",
       "      <th>geometry_x</th>\n",
       "      <th>index_right_x</th>\n",
       "      <th>neighbourhood_x</th>\n",
       "      <th>station_id_y</th>\n",
       "      <th>station_name_y</th>\n",
       "      <th>latitude_y</th>\n",
       "      <th>longitude_y</th>\n",
       "      <th>geometry_y</th>\n",
       "      <th>index_right_y</th>\n",
       "      <th>neighbourhood_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-04-13 13:49:59</td>\n",
       "      <td>2023-04-13 13:55:04</td>\n",
       "      <td>innovation_lab___125_western_ave_at_batten_way</td>\n",
       "      <td>soldiers_field_park___111_western_ave</td>\n",
       "      <td>A32011</td>\n",
       "      <td>innovation_lab___125_western_ave_at_batten_way</td>\n",
       "      <td>42.363713</td>\n",
       "      <td>-71.124598</td>\n",
       "      <td>POINT (-71.12460 42.36371)</td>\n",
       "      <td>24.0</td>\n",
       "      <td>allston</td>\n",
       "      <td>A32006</td>\n",
       "      <td>soldiers_field_park___111_western_ave</td>\n",
       "      <td>42.364263</td>\n",
       "      <td>-71.118276</td>\n",
       "      <td>POINT (-71.11828 42.36426)</td>\n",
       "      <td>24.0</td>\n",
       "      <td>allston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-04-25 09:44:38</td>\n",
       "      <td>2023-04-25 09:51:28</td>\n",
       "      <td>museum_of_science</td>\n",
       "      <td>one_broadway_/_kendall_sq_at_main_st_/_3rd_st</td>\n",
       "      <td>M32045</td>\n",
       "      <td>museum_of_science</td>\n",
       "      <td>42.367690</td>\n",
       "      <td>-71.071163</td>\n",
       "      <td>POINT (-71.07116 42.36769)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M32003</td>\n",
       "      <td>one_broadway_/_kendall_sq_at_main_st_/_3rd_st</td>\n",
       "      <td>42.362242</td>\n",
       "      <td>-71.083111</td>\n",
       "      <td>POINT (-71.08311 42.36224)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-04-24 18:39:31</td>\n",
       "      <td>2023-04-24 18:58:05</td>\n",
       "      <td>new_balance___20_guest_st</td>\n",
       "      <td>hms/hsph___avenue_louis_pasteur_at_longwood_ave</td>\n",
       "      <td>D32001</td>\n",
       "      <td>new_balance___20_guest_st</td>\n",
       "      <td>42.357329</td>\n",
       "      <td>-71.146735</td>\n",
       "      <td>POINT (-71.14674 42.35733)</td>\n",
       "      <td>17.0</td>\n",
       "      <td>brighton</td>\n",
       "      <td>B32003</td>\n",
       "      <td>hms/hsph___avenue_louis_pasteur_at_longwood_ave</td>\n",
       "      <td>42.337417</td>\n",
       "      <td>-71.102861</td>\n",
       "      <td>POINT (-71.10286 42.33742)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>longwood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-04-04 19:25:31</td>\n",
       "      <td>2023-04-04 19:32:14</td>\n",
       "      <td>museum_of_science</td>\n",
       "      <td>gore_street_at_lambert_street</td>\n",
       "      <td>M32045</td>\n",
       "      <td>museum_of_science</td>\n",
       "      <td>42.367690</td>\n",
       "      <td>-71.071163</td>\n",
       "      <td>POINT (-71.07116 42.36769)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M32081</td>\n",
       "      <td>gore_street_at_lambert_street</td>\n",
       "      <td>42.373080</td>\n",
       "      <td>-71.086342</td>\n",
       "      <td>POINT (-71.08634 42.37308)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-04-11 08:36:14</td>\n",
       "      <td>2023-04-11 08:52:39</td>\n",
       "      <td>museum_of_science</td>\n",
       "      <td>columbus_ave_at_w_canton_st</td>\n",
       "      <td>M32045</td>\n",
       "      <td>museum_of_science</td>\n",
       "      <td>42.367690</td>\n",
       "      <td>-71.071163</td>\n",
       "      <td>POINT (-71.07116 42.36769)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C32077</td>\n",
       "      <td>columbus_ave_at_w_canton_st</td>\n",
       "      <td>42.344742</td>\n",
       "      <td>-71.076482</td>\n",
       "      <td>POINT (-71.07648 42.34474)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>south_end</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296286</th>\n",
       "      <td>2023-04-18 09:10:33</td>\n",
       "      <td>2023-04-18 09:14:04</td>\n",
       "      <td>mit_at_mass_ave_/_amherst_st</td>\n",
       "      <td>galileo_galilei_way_at_main_street</td>\n",
       "      <td>M32006</td>\n",
       "      <td>mit_at_mass_ave_/_amherst_st</td>\n",
       "      <td>42.358100</td>\n",
       "      <td>-71.093198</td>\n",
       "      <td>POINT (-71.09320 42.35810)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M32072</td>\n",
       "      <td>galileo_galilei_way_at_main_street</td>\n",
       "      <td>42.363004</td>\n",
       "      <td>-71.089740</td>\n",
       "      <td>POINT (-71.08974 42.36300)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296287</th>\n",
       "      <td>2023-04-18 08:18:38</td>\n",
       "      <td>2023-04-18 08:23:07</td>\n",
       "      <td>mit_at_mass_ave_/_amherst_st</td>\n",
       "      <td>galileo_galilei_way_at_main_street</td>\n",
       "      <td>M32006</td>\n",
       "      <td>mit_at_mass_ave_/_amherst_st</td>\n",
       "      <td>42.358100</td>\n",
       "      <td>-71.093198</td>\n",
       "      <td>POINT (-71.09320 42.35810)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M32072</td>\n",
       "      <td>galileo_galilei_way_at_main_street</td>\n",
       "      <td>42.363004</td>\n",
       "      <td>-71.089740</td>\n",
       "      <td>POINT (-71.08974 42.36300)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296288</th>\n",
       "      <td>2023-04-17 11:34:35</td>\n",
       "      <td>2023-04-17 11:49:10</td>\n",
       "      <td>mit_at_mass_ave_/_amherst_st</td>\n",
       "      <td>beacon_st_at_washington_/_kirkland</td>\n",
       "      <td>M32006</td>\n",
       "      <td>mit_at_mass_ave_/_amherst_st</td>\n",
       "      <td>42.358100</td>\n",
       "      <td>-71.093198</td>\n",
       "      <td>POINT (-71.09320 42.35810)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296289</th>\n",
       "      <td>2023-04-06 17:26:11</td>\n",
       "      <td>2023-04-06 17:34:44</td>\n",
       "      <td>central_sq_post_office_/_cambridge_city_hall_a...</td>\n",
       "      <td>beacon_st_at_washington_/_kirkland</td>\n",
       "      <td>M32012</td>\n",
       "      <td>central_sq_post_office_/_cambridge_city_hall_a...</td>\n",
       "      <td>42.366426</td>\n",
       "      <td>-71.105495</td>\n",
       "      <td>POINT (-71.10550 42.36643)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296290</th>\n",
       "      <td>2023-04-22 12:16:07</td>\n",
       "      <td>2023-04-22 12:23:59</td>\n",
       "      <td>central_sq_post_office_/_cambridge_city_hall_a...</td>\n",
       "      <td>galileo_galilei_way_at_main_street</td>\n",
       "      <td>M32012</td>\n",
       "      <td>central_sq_post_office_/_cambridge_city_hall_a...</td>\n",
       "      <td>42.366426</td>\n",
       "      <td>-71.105495</td>\n",
       "      <td>POINT (-71.10550 42.36643)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M32072</td>\n",
       "      <td>galileo_galilei_way_at_main_street</td>\n",
       "      <td>42.363004</td>\n",
       "      <td>-71.089740</td>\n",
       "      <td>POINT (-71.08974 42.36300)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>296291 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 started_at             ended_at  \\\n",
       "0       2023-04-13 13:49:59  2023-04-13 13:55:04   \n",
       "1       2023-04-25 09:44:38  2023-04-25 09:51:28   \n",
       "2       2023-04-24 18:39:31  2023-04-24 18:58:05   \n",
       "3       2023-04-04 19:25:31  2023-04-04 19:32:14   \n",
       "4       2023-04-11 08:36:14  2023-04-11 08:52:39   \n",
       "...                     ...                  ...   \n",
       "296286  2023-04-18 09:10:33  2023-04-18 09:14:04   \n",
       "296287  2023-04-18 08:18:38  2023-04-18 08:23:07   \n",
       "296288  2023-04-17 11:34:35  2023-04-17 11:49:10   \n",
       "296289  2023-04-06 17:26:11  2023-04-06 17:34:44   \n",
       "296290  2023-04-22 12:16:07  2023-04-22 12:23:59   \n",
       "\n",
       "                                       start_station_name  \\\n",
       "0          innovation_lab___125_western_ave_at_batten_way   \n",
       "1                                       museum_of_science   \n",
       "2                               new_balance___20_guest_st   \n",
       "3                                       museum_of_science   \n",
       "4                                       museum_of_science   \n",
       "...                                                   ...   \n",
       "296286                       mit_at_mass_ave_/_amherst_st   \n",
       "296287                       mit_at_mass_ave_/_amherst_st   \n",
       "296288                       mit_at_mass_ave_/_amherst_st   \n",
       "296289  central_sq_post_office_/_cambridge_city_hall_a...   \n",
       "296290  central_sq_post_office_/_cambridge_city_hall_a...   \n",
       "\n",
       "                                       end_station_name station_id_x  \\\n",
       "0                 soldiers_field_park___111_western_ave       A32011   \n",
       "1         one_broadway_/_kendall_sq_at_main_st_/_3rd_st       M32045   \n",
       "2       hms/hsph___avenue_louis_pasteur_at_longwood_ave       D32001   \n",
       "3                         gore_street_at_lambert_street       M32045   \n",
       "4                           columbus_ave_at_w_canton_st       M32045   \n",
       "...                                                 ...          ...   \n",
       "296286               galileo_galilei_way_at_main_street       M32006   \n",
       "296287               galileo_galilei_way_at_main_street       M32006   \n",
       "296288               beacon_st_at_washington_/_kirkland       M32006   \n",
       "296289               beacon_st_at_washington_/_kirkland       M32012   \n",
       "296290               galileo_galilei_way_at_main_street       M32012   \n",
       "\n",
       "                                           station_name_x  latitude_x  \\\n",
       "0          innovation_lab___125_western_ave_at_batten_way   42.363713   \n",
       "1                                       museum_of_science   42.367690   \n",
       "2                               new_balance___20_guest_st   42.357329   \n",
       "3                                       museum_of_science   42.367690   \n",
       "4                                       museum_of_science   42.367690   \n",
       "...                                                   ...         ...   \n",
       "296286                       mit_at_mass_ave_/_amherst_st   42.358100   \n",
       "296287                       mit_at_mass_ave_/_amherst_st   42.358100   \n",
       "296288                       mit_at_mass_ave_/_amherst_st   42.358100   \n",
       "296289  central_sq_post_office_/_cambridge_city_hall_a...   42.366426   \n",
       "296290  central_sq_post_office_/_cambridge_city_hall_a...   42.366426   \n",
       "\n",
       "        longitude_x                  geometry_x  index_right_x  \\\n",
       "0        -71.124598  POINT (-71.12460 42.36371)           24.0   \n",
       "1        -71.071163  POINT (-71.07116 42.36769)            NaN   \n",
       "2        -71.146735  POINT (-71.14674 42.35733)           17.0   \n",
       "3        -71.071163  POINT (-71.07116 42.36769)            NaN   \n",
       "4        -71.071163  POINT (-71.07116 42.36769)            NaN   \n",
       "...             ...                         ...            ...   \n",
       "296286   -71.093198  POINT (-71.09320 42.35810)            NaN   \n",
       "296287   -71.093198  POINT (-71.09320 42.35810)            NaN   \n",
       "296288   -71.093198  POINT (-71.09320 42.35810)            NaN   \n",
       "296289   -71.105495  POINT (-71.10550 42.36643)            NaN   \n",
       "296290   -71.105495  POINT (-71.10550 42.36643)            NaN   \n",
       "\n",
       "       neighbourhood_x station_id_y  \\\n",
       "0              allston       A32006   \n",
       "1                  NaN       M32003   \n",
       "2             brighton       B32003   \n",
       "3                  NaN       M32081   \n",
       "4                  NaN       C32077   \n",
       "...                ...          ...   \n",
       "296286             NaN       M32072   \n",
       "296287             NaN       M32072   \n",
       "296288             NaN          NaN   \n",
       "296289             NaN          NaN   \n",
       "296290             NaN       M32072   \n",
       "\n",
       "                                         station_name_y  latitude_y  \\\n",
       "0                 soldiers_field_park___111_western_ave   42.364263   \n",
       "1         one_broadway_/_kendall_sq_at_main_st_/_3rd_st   42.362242   \n",
       "2       hms/hsph___avenue_louis_pasteur_at_longwood_ave   42.337417   \n",
       "3                         gore_street_at_lambert_street   42.373080   \n",
       "4                           columbus_ave_at_w_canton_st   42.344742   \n",
       "...                                                 ...         ...   \n",
       "296286               galileo_galilei_way_at_main_street   42.363004   \n",
       "296287               galileo_galilei_way_at_main_street   42.363004   \n",
       "296288                                              NaN         NaN   \n",
       "296289                                              NaN         NaN   \n",
       "296290               galileo_galilei_way_at_main_street   42.363004   \n",
       "\n",
       "        longitude_y                  geometry_y  index_right_y neighbourhood_y  \n",
       "0        -71.118276  POINT (-71.11828 42.36426)           24.0         allston  \n",
       "1        -71.083111  POINT (-71.08311 42.36224)            NaN             NaN  \n",
       "2        -71.102861  POINT (-71.10286 42.33742)            3.0        longwood  \n",
       "3        -71.086342  POINT (-71.08634 42.37308)            NaN             NaN  \n",
       "4        -71.076482  POINT (-71.07648 42.34474)            9.0       south_end  \n",
       "...             ...                         ...            ...             ...  \n",
       "296286   -71.089740  POINT (-71.08974 42.36300)            NaN             NaN  \n",
       "296287   -71.089740  POINT (-71.08974 42.36300)            NaN             NaN  \n",
       "296288          NaN                        None            NaN             NaN  \n",
       "296289          NaN                        None            NaN             NaN  \n",
       "296290   -71.089740  POINT (-71.08974 42.36300)            NaN             NaN  \n",
       "\n",
       "[296291 rows x 18 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_df = read_file('data/Boston_Neighborhoods.geojson')\n",
    "#        poly_df = poly_df[poly_df['District'] == 'Boston']\n",
    "poly_df = poly_df[['Name', 'geometry']]\n",
    "poly_df.columns = ['neighbourhood', 'geometry']\n",
    "poly_df['neighbourhood'] = poly_df['neighbourhood'].str.lower()\n",
    "poly_df['neighbourhood'] = poly_df['neighbourhood'].str.replace(' ', '_')\n",
    "poly_df['neighbourhood'] = poly_df['neighbourhood'].str.replace('-', '_')\n",
    "poly_df['neighbourhood'] = poly_df['neighbourhood'].str.replace('\\'', '')\n",
    "poly_df['neighbourhood'] = poly_df['neighbourhood'].str.replace('(', '')\n",
    "poly_df['neighbourhood'] = poly_df['neighbourhood'].str.replace(')', '')\n",
    "poly_df['neighbourhood'] = poly_df['neighbourhood'].str.replace('.', '')\n",
    "poly_df['neighbourhood'] = poly_df['neighbourhood'].str.replace('&', 'and')\n",
    "# Here is where manual was added\n",
    "stations = pd.read_csv('data/current_bluebikes_stations.csv')\n",
    "#stations = stations[['Station ID', 'Station Name', 'Latitude', 'Longitude']]\n",
    "stations = stations[['Number', 'Name', 'Latitude', 'Longitude']]\n",
    "stations.columns = ['station_id', 'station_name', 'latitude', 'longitude']\n",
    "stations['station_name'] = stations['station_name'].str.lower()\n",
    "stations['station_name'] = stations['station_name'].str.replace(' ', '_')\n",
    "stations['station_name'] = stations['station_name'].str.replace('-', '_')\n",
    "stations['station_name'] = stations['station_name'].str.replace('\\'', '')\n",
    "stations['station_name'] = stations['station_name'].str.replace('(', '')\n",
    "stations['station_name'] = stations['station_name'].str.replace(')', '')\n",
    "stations['station_name'] = stations['station_name'].str.replace('.', '')\n",
    "stations['station_name'] = stations['station_name'].str.replace('&', 'and')\n",
    "# Here, the loop began again, forcing manual changes\n",
    "stations_geo = GeoDataFrame(stations, geometry=points_from_xy(stations.longitude, stations.latitude))\n",
    "stations_geo.set_crs(epsg='4326', inplace=True)\n",
    "joined_df = stations_geo.sjoin(poly_df, how=\"left\")\n",
    "#grab_df = joined_df[['Name_left', 'Name_right', 'District']]\n",
    "#matched_pairs_with_pandas = grab_df[grab_df['District'] == 'Boston']\n",
    "#matched_pairs_with_pandas.columns = ['station', 'neighbourhood', 'District']\n",
    "# Create a SparkSession\n",
    "#spark = SparkSession.builder.appName(\"BlueBikes\").getOrCreate()\n",
    "# Create a schema for the dataframe\n",
    "#schema = StructType([])\n",
    "# Load the CSV file into a dataframe\n",
    "#journeys = spark.read.csv(journeys_path, header=True, schema=schema)\n",
    "journeys_pandas_df = pd.read_csv('data/202304-bluebikes-tripdata.csv')\n",
    "#started_at was actual name\n",
    "journeys_pandas_df = journeys_pandas_df[['started_at', 'ended_at', 'start_station_name', 'end_station_name']]\n",
    "journeys_pandas_df.columns = ['started_at', 'ended_at', 'start_station_name', 'end_station_name']\n",
    "journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.lower()\n",
    "journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace(' ', '_')\n",
    "journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('-', '_')\n",
    "journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('\\'', '')\n",
    "journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('(', '')\n",
    "journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace(')', '')\n",
    "journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('.', '')\n",
    "journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('&', 'and')\n",
    "journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.lower()\n",
    "journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace(' ', '_')\n",
    "journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('-', '_')\n",
    "journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('\\'', '')\n",
    "journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('(', '')\n",
    "journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace(')', '')\n",
    "journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('.', '')\n",
    "journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('&', 'and')\n",
    "#journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace(' ', '_')\n",
    "#journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace(' ', '_')\n",
    "#journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('-', '_')\n",
    "#journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('-', '_')\n",
    "#journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('\\'', '')\n",
    "#journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('\\'', '')\n",
    "#journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('(', '')\n",
    "#journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('(', '')\n",
    "#journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace(')', '')\n",
    "#journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace(')', '')\n",
    "#journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('.', '')\n",
    "#journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('.', '')\n",
    "#journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('&', 'and')\n",
    "#journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('&', 'and')\n",
    "#journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace(' ', '_')\n",
    "#journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace(' ', '_')\n",
    "#journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('-', '_')\n",
    "#journeys_pandas_df['end_station_name'] = journeys_pandas_df['end_station_name'].str.replace('-', '_')\n",
    "#journeys_pandas_df['start_station_name'] = journeys_pandas_df['start_station_name'].str.replace('\\'', '')\n",
    "#Broke loop here with journeys_enriched call\n",
    "journeys_enriched = pd.merge(journeys_pandas_df, joined_df, how='left', left_on='start_station_name', right_on='station_name')\n",
    "journeys_enriched = pd.merge(journeys_enriched, joined_df, how='left', left_on='end_station_name', right_on='station_name')\n",
    "journeys_enriched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
